{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important library\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import sys\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "import collections\n",
    "import io\n",
    "from IPython.display import Image\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database\n",
      "\t->host='localhost' dbname='WTP_NUS_library'\n",
      "Connected!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# connect to database. Postgres must be opened!\n",
    "conn_string = \"host='localhost' dbname='WTP_NUS_library'\"\n",
    "print (\"Connecting to database\\n\t->%s\" % (conn_string))\n",
    "conn = psycopg2.connect(conn_string)\n",
    "print (\"Connected!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all users\n",
    "db_users = pd.read_sql_query (\"SELECT * FROM \\\"user\\\"\", conn)\n",
    "# number of submission for each users\n",
    "db_count_submissions = pd.read_sql_query(\"\"\"SELECT author_id,COUNT(scenario.id) as n FROM SCENARIO GROUP BY author_id ORDER BY author_id\"\"\",conn)\n",
    "# latest submission\n",
    "db_scenarios_late = pd.read_sql_query(\"SELECT id, author_id, last_update, description, image, encode(geometry,'escape') as geo FROM scenario as a WHERE id = (SELECT max(b.id) FROM scenario as b where a.author_id = b.author_id) ORDER BY author_id\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all user actions\n",
    "db_user_scenario_load =pd.read_sql_query( \"SELECT * FROM user_scenario_load\",conn)\n",
    "db_user_scenario_update =pd.read_sql_query( \"SELECT * FROM user_scenario_update\",conn)\n",
    "db_user_scenario_action =pd.read_sql_query( \"SELECT * FROM user_scenario_action\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cross feedback\n",
    "db_criterion = pd.read_sql_query( \"SELECT * FROM criterion\",conn)\n",
    "db_vote = pd.read_sql_query( \"SELECT * FROM vote\",conn)\n",
    "db_peer_review = pd.read_sql_query( \"SELECT * FROM review\",conn)\n",
    "db_expert_review = pd.read_sql_query(\"SELECT * FROM  expert_review\",conn)\n",
    "db_voter_score = pd.read_sql_query(\"SELECT * FROM vote_rating\", conn)\n",
    "db_voter_scenario = pd.read_sql_query(\"SELECT * FROM scenario\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final grade and ratings\n",
    "db_grade = pd.read_sql_query(\"SELECT * FROM current_scenario\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Short cuts for important tables\n",
    "ld = db_user_scenario_load\n",
    "ud = db_user_scenario_update\n",
    "ac = db_user_scenario_action\n",
    "lt = db_scenarios_late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the data analysis..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data and data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the geojson data from all designs\n",
    "\n",
    "regex = re.compile(r'\\\\(?![/u\"])')\n",
    "for i, geo_val in enumerate(db_scenarios_late.geo):\n",
    "  #Select if Exercise 1a, 1b or 1c should be chosen. It is the 19th letter in each db_scenarios_late.geo file\n",
    "  if lt.geo[i][19]=='a':\n",
    "    fixed = regex.sub(r\"\\\\\\\\\", geo_val) #remove the \"/\" in some fields to for json conversion\n",
    "    b = json.loads(fixed)\n",
    "    # this would remove an empty MultiLineString object so that it can be displayed in the current qua-viewer. However the shape is still distorted because of the limitation of allowed vertex\n",
    "    with open(\"output/geo_a_\" + str(db_scenarios_late.loc[i,'author_id']) + \".json\",\"w\") as f:\n",
    "        json.dump(b,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the original geojson file for the exercise\n",
    "geo = gpd.read_file('Exercise_1a_reflex_for_upload.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary with all geojson files for exercise 1a\n",
    "geo_a={}\n",
    "for i,j in enumerate(lt['author_id']):\n",
    "    if lt.geo[i][19]=='a':\n",
    "        geo_a[\"geo_author_{0}\".format(j)]= gpd.read_file('output/geo_a_'+str(j)+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all authors that worked on Exercise 1a\n",
    "author_id_a = []\n",
    "for i,j in enumerate(lt['author_id']):\n",
    "    if lt.geo[i][19]=='a':\n",
    "        author_id_a.append(j)\n",
    "# Delete buggy submissions (manually detected)\n",
    "y=[16]\n",
    "author_id_a = sorted(list(set(author_id_a).difference(set(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data correction: For 'Chinatown, Central Area', the precinctID is missing in the original data set\n",
    "for j in list(author_id_a):\n",
    "    for i in range(0,len(geo_a['geo_author_'+str(j)])):\n",
    "        if geo_a['geo_author_'+str(j)]['precinctName'][i] == \"Chinatown, Central Area\":\n",
    "            geo_a['geo_author_'+str(j)].loc[i,'precinctID'] = 102\n",
    "        if geo_a['geo_author_'+str(j)]['name'][i] == \"greenery small\":\n",
    "            geo_a['geo_author_'+str(j)].loc[i,'precinctID'] = 401\n",
    "        if geo_a['geo_author_'+str(j)]['name'][i] == \"greenery medium\":\n",
    "            geo_a['geo_author_'+str(j)].loc[i,'precinctID'] = 402\n",
    "        if geo_a['geo_author_'+str(j)]['name'][i] == \"greenery large\":\n",
    "            geo_a['geo_author_'+str(j)].loc[i,'precinctID'] = 403\n",
    "#Overwrite existing .json files with updated precinctID\n",
    "    with open('output/geo_a_'+str(j)+'.json', 'w') as f:\n",
    "        f.write(geo_a['geo_author_'+str(j)].to_json())\n",
    "#Change original geojson file with added precinctID for the greenery\n",
    "for i in range(1,len(geo)):\n",
    "    if geo.loc[i,'name'] == 'greenery small':\n",
    "        geo.loc[i,'precinctID'] = 401\n",
    "    if geo.loc[i,'name'] == 'greenery medium':\n",
    "        geo.loc[i,'precinctID'] = 402\n",
    "    if geo.loc[i,'name'] == 'greenery large':\n",
    "        geo.loc[i,'precinctID'] = 403\n",
    "with open('Exercise_1a_reflex_for_upload_updated.json', 'w') as f:\n",
    "        f.write(geo.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the frequency of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function for the the number of elements placed\n",
    "\n",
    "def counter_old(file,obj):\n",
    "    #Check if file is a string\n",
    "    if isinstance(file, str) == False:\n",
    "        print('First variable must be a string variable')\n",
    "    \n",
    "    #Extract the integers/numbers out of a string\n",
    "    import re\n",
    "    author_id = re.findall(r'\\d+', file)\n",
    "\n",
    "    import geopandas as gpd\n",
    "    file = gpd.read_file('output/'+file+'.json')\n",
    "    #Here it is important to take the updated version of the original source file as 'greenery' needs values for 'precinctID'.\n",
    "    geo = gpd.read_file('Exercise_1a_reflex_for_upload_updated.json')\n",
    "    \n",
    "    \n",
    "    if obj == 'ALL':\n",
    "        #choose all buildings typologies, incl. greenery\n",
    "        colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303,401,402,403]\n",
    "    if obj == 'buildings':\n",
    "        #choose all building typologies\n",
    "        colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "    if obj == 'low-rise':\n",
    "        #choose all low-rise\n",
    "        colnames_num = [101,102]\n",
    "    if obj == 'mid-rise':\n",
    "        #choose all mid-rise\n",
    "        colnames_num = [201,202,301]\n",
    "    if obj == 'high-rise':\n",
    "        #choose all high-rise\n",
    "        colnames_num = [203,204,205,206,207,302,303]\n",
    "    if obj == 'HDB':\n",
    "        #choose all HDB\n",
    "        colnames_num = [201,202,203,204,205,206,207]\n",
    "    if obj == 'Condo':\n",
    "        #choose all Condo\n",
    "        colnames_num = [301,302,303]\n",
    "    if obj == 'mixed-use':\n",
    "        #choose all building typologies that have a mixed-use\n",
    "        colnames_num = [102,202,203,204]\n",
    "    if obj == 'green_elements':\n",
    "        #choose all building typologies that have a green elements\n",
    "        colnames_num = [401,402,403]\n",
    "    if obj in [101,102,201,202,203,204,205,206,207,301,302,303,401,402,403]:\n",
    "        #choose the specific typology\n",
    "        colnames_num = [obj]\n",
    "        \n",
    "    #Create colnames for dataframe\n",
    "    colnames=[]\n",
    "    for i in colnames_num:\n",
    "        colnames.append('count_'+str(i))\n",
    "    \n",
    "    import pandas as pd\n",
    "    freq = pd.DataFrame(columns=colnames)  # dataframe\n",
    "    \n",
    "    import collections\n",
    "    for k in colnames_num:\n",
    "        freq.loc[0,'count_'+str(k)] = collections.Counter(file.precinctID)[k]-collections.Counter(geo.precinctID)[k]\n",
    "\n",
    "    #Adjustment of the frequencies\n",
    "    \n",
    "    # Adjusting count by number of group elements for each precinct typology\n",
    "\n",
    "    if 'count_101' in freq.columns:\n",
    "        freq['count_101']= freq['count_101']/2\n",
    "    if 'count_102' in freq.columns:\n",
    "        freq['count_102'] = freq['count_102']/3\n",
    "    if 'count_201' in freq.columns:\n",
    "        freq['count_201'] = freq['count_201']/2\n",
    "    if 'count_202' in freq.columns:\n",
    "        freq['count_202'] = freq['count_202']/3\n",
    "    if 'count_203' in freq.columns:\n",
    "        freq['count_203'] = freq['count_203']/4\n",
    "    if 'count_204' in freq.columns:\n",
    "        freq['count_204'] = freq['count_204']/3\n",
    "    if 'count_205' in freq.columns:\n",
    "        freq['count_205'] = freq['count_205']/3\n",
    "    if 'count_206' in freq.columns:\n",
    "        freq['count_206'] = freq['count_206']/2\n",
    "    if 'count_207' in freq.columns:\n",
    "        freq['count_207'] = freq['count_207']/3\n",
    "    if 'count_301' in freq.columns:\n",
    "        freq['count_301'] = freq['count_301']/2\n",
    "    if 'count_302' in freq.columns:\n",
    "        freq['count_302'] = freq['count_302']/3\n",
    "    if 'count_303' in freq.columns:\n",
    "        freq['count_303'] = freq['count_303']/2\n",
    "        \n",
    "    freq.insert(len(colnames),'total', freq.values.sum())\n",
    "    \n",
    "    freq = freq.astype(int)\n",
    "    #Add author_id to the dataframe as first (0th) row\n",
    "    freq.insert(0, 'author_id', author_id, allow_duplicates=False)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating averages for specific objects and object groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the average for specific types, here just one example\n",
    "\n",
    "# Defining which authors contributed useful submissions\n",
    "# Delete non-useful submissions (manually decided, quite strict), author_id 16 was already deleted before\n",
    "x = [11,12,18,20,26,27,28,50,53,55,94,106,108,109,116,117,122,120,135,137]\n",
    "author_id_a = sorted(list(set(author_id_a).difference(set(x))))\n",
    "#author_id_a = pd.DataFrame(author_id_a, columns = ['author_id_a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_old_mean(authors,obj):\n",
    "   \n",
    "    #Input for authors: list of author_id\n",
    "    s = pd.DataFrame()\n",
    "    for i in authors:\n",
    "        s = s.append(counter_old('geo_a_'+str(i),obj))\n",
    "    #s = float(s / len(authors))\n",
    "    col = list(s.columns.values)\n",
    "\n",
    "    t = s[col[1:len(col)]].mean(axis=0)\n",
    "    t = list(t)\n",
    "    return col[1:len(col)], t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = counter_old_mean(author_id_a,'ALL')[0]\n",
    "\n",
    "colnames = []\n",
    "\n",
    "for k in col:\n",
    "    colnames.append(dic[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for plotting barchar from the average number of objects\n",
    "\n",
    "def counter_old_bar(authors, obj= 'ALL',total = False):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "\n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303,401,402,403]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.name[k]\n",
    "    dic['total']='total'\n",
    "\n",
    "    col, mean_count = counter_old_mean(authors,obj)\n",
    "    \n",
    "    if total == False:\n",
    "        col.remove('total')\n",
    "        del mean_count[-1]\n",
    "    \n",
    "    colnames = []\n",
    "    for k in col:\n",
    "        colnames.append(dic[k])\n",
    "    \n",
    "    plt.bar(np.arange(len(mean_count)),mean_count,align='center', color=['#7A9E7E'])\n",
    "    plt.xticks(np.arange(len(mean_count)),colnames,rotation='vertical')\n",
    "    plt.title(\"Average number of objects\")\n",
    "    #plt.savefig('figures/fig_bar_'+str(i)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Calculating 'Number Of Units'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def units_old(file):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col = counter_old(file,'buildings')\n",
    "    col = col.drop('total',axis=1)\n",
    "    col = col.drop('author_id',axis=1)\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.numberOfUnits[k]\n",
    "    \n",
    "    s = 0\n",
    "    for i in range(0,len(col.columns)):\n",
    "        s += dic[col.columns.values[i]] * col[col.columns.values[i]][0]\n",
    "    s = int(s)   \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def units_old_mean(authors):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col, val = counter_old_mean(authors,'buildings')\n",
    "    del col[-1]\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.numberOfUnits[k]\n",
    "    \n",
    "    s = 0\n",
    "    for i in range(0,len(col)):\n",
    "        s += (dic[col[i]] * val[i])\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the total tile area, total plot area and GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_area_old(file):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col = counter_old(file,'buildings')\n",
    "    col = col.drop('total',axis=1)\n",
    "    col = col.drop('author_id',axis=1)\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.tileArea[k]\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(0,len(col.columns)):\n",
    "        a += dic[col.columns.values[i]] * col[col.columns.values[i]][0]  \n",
    "        \n",
    "    part = round((a / 1.7) * 100,2)\n",
    "    \n",
    "    return a, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_area_old_mean(authors):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col, val = counter_old_mean(authors,'buildings')\n",
    "    del col[-1]\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.tileArea[k]\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(0,len(col)):\n",
    "        a += (dic[col[i]] * val[i])\n",
    "        \n",
    "    part = round((a / 1.7) * 100,2)\n",
    "    \n",
    "    return a, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_area_old(file):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col = counter_old(file,'buildings')\n",
    "    col = col.drop('total',axis=1)\n",
    "    col = col.drop('author_id',axis=1)\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.plotArea[k]\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(0,len(col.columns)):\n",
    "        a += dic[col.columns.values[i]] * col[col.columns.values[i]][0]  \n",
    "        \n",
    "    part = round((a / 1.7) * 100,2)\n",
    "    \n",
    "    return a, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_area_old_mean(authors):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col, val = counter_old_mean(authors,'buildings')\n",
    "    del col[-1]\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.plotArea[k]\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(0,len(col)):\n",
    "        a += (dic[col[i]] * val[i])\n",
    "        \n",
    "    part = round((a / 1.7) * 100,2)\n",
    "    \n",
    "    return a, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpr_old(file):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col = counter_old(file,'buildings')\n",
    "    col = col.drop('total',axis=1)\n",
    "    col = col.drop('author_id',axis=1)\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.floorArea[k]\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(0,len(col.columns)):\n",
    "        a += dic[col.columns.values[i]] * col[col.columns.values[i]][0]  \n",
    "        \n",
    "    gpr = round(a / 1.7,2)\n",
    "    \n",
    "    return gpr, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpr_old_mean(authors):\n",
    "    \n",
    "    pf = pd.read_csv('Precincts_final.csv')\n",
    "    \n",
    "    col, val = counter_old_mean(authors,'buildings')\n",
    "    del col[-1]\n",
    "    \n",
    "    colnames_num = [101,102,201,202,203,204,205,206,207,301,302,303]\n",
    "\n",
    "    dic = {}\n",
    "    for k,l in enumerate(colnames_num):\n",
    "        dic['count_'+str(l)]=pf.floorArea[k]\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(0,len(col)):\n",
    "        a += (dic[col[i]] * val[i])\n",
    "        \n",
    "    gpr = round(a / 1.7,2)\n",
    "    \n",
    "    return gpr, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29, 59, 61, 68, 79, 83, 87, 89, 90, 92, 93, 105, 107, 110, 111, 112, 123, 130]"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_area_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in author_id_a:\n",
    "    x.append(units_old('geo_a_'+str(i)))\n",
    "    y.append(tile_area_old('geo_a_'+str(i))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cbbaa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120bee208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x.append(70000)\n",
    "#y.append(4.5)\n",
    "#If 70000 units should be built on this ground (4.5 as far as I know), 26444 must be in average built on that site (size: 1.7).\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "plt.boxplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Gross Flot Ratio:\n",
    "# https://en.wikipedia.org/wiki/Floor_area_(building)#In_Singapore\n",
    "# The NUS campus and ONLINE study worked with two different study areas:\n",
    "# Study area NUS Campus [in square kilometer]\n",
    "area_total = 1.7\n",
    "#Study areas for online study\n",
    "area_1 = 0.546715\n",
    "area_2 = 0.322409\n",
    "#Please note that some participants just built on area_1 (where the spawn point of objects was)\n",
    "# The areas for each object can be found in prec_desc\n",
    "# Explanation: plotArea: area of the building plot (without the surrounding green), floorArea: levels*plotArea, \n",
    "# tileArea: area of the platform (greenery around building + plotArea), floorAreaRatio: floorArea/tileArea\n",
    "# Greeneries do not need to be considered as they do not count for the GFA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
